# TKR News Gather - Canadian Provincial News Processing System
# Production-ready news aggregation and AI processing platform
# Serverless deployment on RunPod with comprehensive security features

# Project Metadata - Current production system status
project:
  name: "TKR News Gather"
  version: "0.1.0"
  description: "Canadian provincial news aggregation and AI processing system with serverless deployment and multi-personality AI hosts"
  author: "TKR News Team"
  role: "News Processing & AI Analysis Platform"
  timestamp: "2025-01-06"
  status: "production-ready"
  
  # External systems and references
  references:
    python_implementation: "_project/_ref/python-implementation.md"
    supabase_setup: "_project/_ref/supabase-setup.md"
    project_structure: "_project/_ref/tkr-news-gather-structure.md"
    anthropic_api: "https://docs.anthropic.com/claude/reference"
    runpod_docs: "_project/_ref/runpod-docs/"
    deployment_guide: "DEPLOYMENT.md"
    security_guide: "SECURITY.md"
  
  # Repository information
  repository:
    type: "git"
    url: "https://github.com/tkr-projects/tkr-news-gather"
    branch: "main"
    license: "MIT"
  
  # Project infrastructure
  infrastructure:
    hosting: "RunPod Serverless"
    database: "Supabase PostgreSQL"
    containerization: "Docker"
    ci_cd: "GitHub Actions Ready"
    environments:
      - name: "development"
        url: "http://localhost:8000"
        auth: "Optional"
      - name: "staging"  
        url: "TBD - RunPod endpoint"
        auth: "JWT Required"
      - name: "production"
        url: "TBD - RunPod endpoint" 
        auth: "JWT + Rate Limiting"

# Technology Stack - Production implementation details
tech_stack:
  # Backend technology (primary service)
  backend:
    framework: "FastAPI"
    language: "Python 3.9+"
    runtime: "asyncio + uvicorn"
    package_manager: "poetry"
    architecture: "Dual API (basic + secure)"
    
    # Core dependencies with security patches
    key_libraries:
      - name: "fastapi"
        version: ">=0.108.0"
        purpose: "High-performance async web framework"
      - name: "anthropic" 
        version: ">=0.25.0"
        purpose: "Claude AI API for content processing with 3 personalities"
      - name: "crawl4ai"
        version: ">=0.3.0"
        purpose: "Advanced web scraping with JavaScript support"
      - name: "supabase"
        version: ">=2.3.0"
        purpose: "PostgreSQL database client with auth"
      - name: "feedparser"
        version: ">=6.0.10"
        purpose: "Google News RSS feed parsing (secure version)"
      - name: "httpx"
        version: ">=0.26.0"
        purpose: "Modern async HTTP client"
      - name: "python-jose"
        version: ">=3.3.0"
        purpose: "JWT token handling and authentication"
      - name: "slowapi"
        version: ">=0.1.9"
        purpose: "Rate limiting middleware"
      - name: "runpod"
        version: ">=1.6.0"
        purpose: "Serverless deployment SDK"
    
    # Database and storage
    database: "PostgreSQL (Supabase)"
    storage_options:
      - "Supabase PostgreSQL with RLS"
      - "Local filesystem storage"
      - "Future: Supabase Storage for audio files"
    
    # API architecture
    apis:
      basic_api:
        type: "REST"
        base_url: "/api/v1" 
        authentication: "Optional API keys"
        features: ["Health checks", "News fetching", "AI processing", "Data queries"]
      secure_api:
        type: "REST"
        base_url: "/api/v1"
        authentication: "JWT + Role-based access"
        features: ["User registration", "Protected endpoints", "Rate limiting", "Input validation"]
        roles: ["user", "editor", "admin"]
  
  # Deployment technology
  deployment:
    strategy: "Serverless containerization"
    platform: "RunPod Serverless"
    containerization: 
      technology: "Docker"
      registry: "Docker Hub"
      multi_stage: true
      security_scanning: true
    automation:
      deployment_script: "deploy.py"
      features: ["Interactive setup", "Credential generation", "API automation", "Testing"]
    
    # Infrastructure as code
    infrastructure:
      - "Dockerfile for containerization"
      - "docker-compose.yml for local development"
      - "RunPod template creation via API"
      - "Automated endpoint provisioning"

# Data Flow Architecture - News processing pipeline
data_flow:
  # Core processing pipeline
  patterns:
    core_strategy: "Multi-stage async news processing pipeline"
    data_sources: "Google News RSS + web scraping + AI processing"
    persistence: "Dual storage (database + filesystem)"
    deployment: "Serverless function execution"
  
  # Data sources and processing stages
  processing_pipeline:
    stage_1:
      name: "News Collection"
      component: "google_news_client.py"
      description: "Fetch RSS feeds for all 13 Canadian provinces/territories"
      output: "Structured news metadata with URLs"
    
    stage_2:
      name: "Content Scraping"
      component: "article_scraper.py" 
      description: "Concurrent web scraping using Crawl4ai"
      features: ["JavaScript support", "Timeout handling", "Concurrent processing"]
      output: "Full article content and metadata"
    
    stage_3:
      name: "AI Processing"
      component: "news_processor.py"
      description: "Multi-personality content processing with Claude"
      personalities:
        - "Professional News Anchor (authoritative, objective)"
        - "Friendly Neighbor (warm, conversational)"  
        - "1940s Newsreel Announcer (dramatic, theatrical)"
      output: "Processed content ready for audio generation"
    
    stage_4:
      name: "Data Persistence"
      components: ["supabase_client.py", "local_storage.py"]
      description: "Dual storage with database and filesystem options"
      features: ["Row-level security", "Efficient indexing", "Local backup"]
  
  # Data storage strategy
  storage:
    database_schema:
      news_sessions: "Collection metadata by province/date"
      articles: "Individual news articles with content"
      processed_articles: "AI-processed content by personality"
      audio_files: "Future audio generation metadata"
    security:
      authentication: "Row-level security policies"
      access_control: "Role-based permissions"
      encryption: "At-rest and in-transit"
  
  # Caching and performance
  performance:
    concurrent_scraping: "Up to 10 simultaneous requests"
    request_timeout: "30 seconds per article"
    rate_limiting: "Respectful scraping with delays"
    connection_pooling: "HTTP client optimization"

# Canadian Provinces Configuration - Complete coverage
provinces:
  supported_regions:
    provinces:
      - "Alberta"
      - "British Columbia"
      - "Manitoba" 
      - "New Brunswick"
      - "Newfoundland and Labrador"
      - "Nova Scotia"
      - "Ontario"
      - "Prince Edward Island"
      - "Quebec"
      - "Saskatchewan"
    territories:
      - "Northwest Territories"
      - "Nunavut"
      - "Yukon"
  
  search_strategy:
    approach: "Multiple search terms per province for content diversity"
    filtering: "Canadian news sources prioritized"
    deduplication: "URL-based article deduplication"
    language_support: "English and French content"

# AI Host Personalities - Production implementation
ai_hosts:
  personalities:
    anchor:
      name: "Professional News Anchor"
      style: "Professional, authoritative, trustworthy broadcast journalism"
      tone: "Clear, measured, objective reporting"
      target_length: "30-60 seconds spoken content"
      use_case: "Formal news broadcasts and official updates"
    
    friend:
      name: "Friendly Neighbor"  
      style: "Warm, conversational, relatable community connection"
      tone: "Casual, friendly, engaging local perspective"
      target_length: "45-75 seconds spoken content"
      use_case: "Community-focused news and local interest stories"
    
    newsreel:
      name: "1940s Newsreel Announcer"
      style: "Dramatic, theatrical, vintage broadcasting"
      tone: "Bold, emphatic, larger-than-life presentation"
      target_length: "30-45 seconds spoken content"
      use_case: "Historical context and dramatic storytelling"
  
  processing_configuration:
    model: "claude-3-haiku-20240307"
    temperature: 0.7
    max_tokens: 2000
    concurrent_processing: true
    error_handling: "Graceful fallback with logging"

# Security Implementation - Production-ready features
security:
  # Authentication and authorization
  authentication:
    method: "JWT tokens with refresh capability"
    session_duration: "Access: 15min, Refresh: 7 days"
    password_hashing: "bcrypt with salt"
    api_key_support: "Optional for basic endpoints"
  
  # Role-based access control
  authorization:
    roles:
      user: ["read_news", "basic_processing"]
      editor: ["user_permissions", "manage_content", "advanced_processing"]
      admin: ["editor_permissions", "user_management", "system_config"]
    scope_enforcement: "Endpoint-level permission checking"
  
  # API security measures
  api_security:
    rate_limiting:
      basic_endpoints: "100 requests/minute"
      processing_endpoints: "10 requests/minute"
      auth_endpoints: "5 requests/minute"
    input_validation: "Pydantic models with strict typing"
    output_sanitization: "Content filtering and escaping"
    security_headers: "CORS, HSTS, X-Frame-Options, CSP"
  
  # Data protection
  data_protection:
    encryption:
      in_transit: "TLS 1.3 for all communications"
      at_rest: "Supabase encryption with RLS"
      tokens: "Cryptographic JWT signing"
    privacy:
      data_collection: "Public news content only"
      user_data: "Minimal collection with consent"
      logging: "Security events and errors only"
  
  # Compliance and auditing
  compliance:
    standards: ["Canadian privacy legislation awareness", "Responsible web scraping"]
    audit_logging: ["Authentication events", "API usage", "Processing requests"]
    vulnerability_management: "Regular dependency updates with security scanning"

# Testing Strategy - Comprehensive quality assurance
testing:
  # Unit testing
  unit:
    framework: "pytest with asyncio support"
    coverage_targets:
      statements: "85%"
      branches: "80%"
      functions: "85%"
    test_categories:
      - "Utility functions and helpers"
      - "Business logic components"
      - "Data processing pipelines"
  
  # Integration testing
  integration:
    framework: "pytest-asyncio"
    test_scenarios:
      - "Complete news gathering pipeline"
      - "AI processing with all personalities"
      - "Database operations and persistence"
      - "Authentication and authorization flows"
      - "Rate limiting and security measures"
  
  # Security testing
  security:
    tools: ["bandit", "safety", "pip-audit"]
    test_areas:
      - "Input validation and sanitization"
      - "Authentication bypass attempts"
      - "SQL injection and XSS prevention"
      - "Rate limiting effectiveness"
  
  # Quality tools
  quality:
    code_formatting: "black"
    import_sorting: "isort"
    linting: "flake8"
    type_checking: "mypy"
    security_scanning: "bandit + safety + pip-audit"

# Deployment Configuration - RunPod serverless automation
deployment:
  # Environment management
  environments:
    development:
      url: "http://localhost:8000"
      database: "Local Supabase or filesystem"
      authentication: "Optional for testing"
      deployment: "Direct uvicorn server"
    
    staging:
      url: "RunPod serverless endpoint"
      database: "Staging Supabase instance"
      authentication: "Full JWT implementation"
      deployment: "Containerized serverless"
    
    production:
      url: "RunPod serverless endpoint"
      database: "Production Supabase instance"
      authentication: "Full security stack"
      deployment: "Containerized serverless with monitoring"
  
  # Automated deployment process
  automation:
    deployment_script: "deploy.py"
    features:
      - "Interactive configuration wizard"
      - "Docker image building and pushing"
      - "RunPod template creation via API"
      - "Endpoint provisioning and testing"
      - "Credential generation and security setup"
      - "Comprehensive deployment documentation"
    
    dependencies:
      - "Docker and docker-compose"
      - "RunPod API access"
      - "Docker Hub registry access"
      - "Supabase project setup"
  
  # Infrastructure components
  infrastructure:
    containerization:
      base_image: "python:3.11-slim"
      optimization: "Multi-stage builds"
      security: "Non-root user, minimal attack surface"
    
    serverless:
      platform: "RunPod"
      scaling: "Automatic based on demand"
      cold_start: "Optimized container startup"
      timeout: "Configurable per endpoint"
    
    monitoring:
      logs: "RunPod dashboard and API"
      metrics: "Request/response tracking"
      alerts: "Error rate and performance thresholds"

# Performance Optimization - Production considerations
performance:
  # Response time targets
  targets:
    api_response: "< 2 seconds for basic endpoints"
    processing_pipeline: "< 60 seconds for full province"
    concurrent_requests: "10 simultaneous scraping operations"
    database_queries: "< 500ms for data retrieval"
  
  # Optimization strategies
  optimization:
    async_processing: "Full async/await implementation"
    connection_pooling: "HTTP client reuse"
    request_batching: "Concurrent article processing"
    caching: "In-memory and database caching"
    lazy_loading: "On-demand resource initialization"
  
  # Monitoring and alerting
  monitoring:
    performance_metrics: ["Response times", "Error rates", "Resource usage"]
    alerting_thresholds: ["API latency > 5s", "Error rate > 5%", "Memory usage > 80%"]
    optimization_targets: ["Cold start reduction", "Memory efficiency", "CPU optimization"]

# Development Workflow - Team collaboration
development:
  # Code quality standards
  code_quality:
    style: "Black formatting with 88-character lines"
    typing: "MyPy strict mode with type hints"
    linting: "Flake8 with security extensions"
    testing: "Pytest with coverage requirements"
  
  # Version control workflow  
  git_workflow:
    branching: "Feature branches with main integration"
    commits: "Conventional commits with semantic versioning"
    reviews: "Required PR reviews for main branch"
    ci_cd: "Automated testing and quality checks"
  
  # Documentation standards
  documentation:
    code: "Comprehensive docstrings and type hints"
    api: "OpenAPI/Swagger auto-generation"
    deployment: "Step-by-step guides with examples"
    security: "Configuration and best practices"

# Future Roadmap - Planned enhancements
roadmap:
  immediate:
    - "Audio file generation from processed content"
    - "Enhanced monitoring and alerting"
    - "Performance optimization and caching"
  
  short_term:
    - "Web interface for news management"
    - "Advanced search and filtering"
    - "Multi-language support enhancement"
  
  long_term:
    - "Real-time news streaming"
    - "Machine learning content classification"
    - "Advanced analytics and reporting"