# TKR News Gatherer - Core Project Configuration
# Python-based news collection and AI processing system for Canadian provincial news
# Fetches news, scrapes content, and processes with AI host personalities

# Project Metadata - High-level information about the project
project:
  name: "TKR News Gatherer"
  version: "0.1.0"
  description: "Python news collection and AI processing system for Canadian provincial news with multiple host personalities"
  author: "TKR Team"
  role: "News aggregation and AI processing service"
  timestamp: "2025-01-04"
  status: "in-progress"
  
  # External systems and references
  references:
    python_implementation: "_project/_ref/python-implementation.md"
    supabase_setup: "_project/_ref/supabase-setup.md"
    project_structure: "_project/_ref/tkr-news-gather-structure.md"
    api_docs: "https://docs.anthropic.com/claude/reference"
    google_news_api: "https://pypi.org/project/pygooglenews/"
  
  # Repository information
  repository:
    type: "git"
    url: "https://github.com/tkr-team/tkr-news-gather"
    branch: "main"
  
  # Project infrastructure
  infrastructure:
    hosting: "RunPod Serverless"
    database: "Supabase PostgreSQL"
    ci_cd: "GitHub Actions"
    environments:
      - name: "development"
        url: "http://localhost:8000"
      - name: "staging"
        url: "https://staging-api.tkr-news.com"
      - name: "production"
        url: "https://api.tkr-news.com"

# Technology Stack - Technical foundation of the project
tech_stack:
  # Backend technology details (primary service)
  backend:
    framework: "FastAPI"
    language: "Python 3.8+"
    runtime: "asyncio"
    package_manager: "pip"
    key_libraries:
      - name: "pygooglenews"
        version: "^0.1.2"
        purpose: "Google News API integration for Canadian news"
      - name: "crawl4ai"
        version: ">=0.2.0"
        purpose: "Advanced web scraping with JavaScript support"
      - name: "beautifulsoup4"
        version: "^4.12.2"
        purpose: "HTML parsing and content extraction"
      - name: "anthropic"
        version: ">=0.18.0"
        purpose: "Claude AI API for content processing"
      - name: "aiohttp"
        version: "^3.9.1"
        purpose: "Async HTTP client for concurrent requests"
      - name: "supabase"
        version: ">=2.0.0"
        purpose: "Database client for data persistence"
    database: "PostgreSQL (Supabase)"
    apis:
      - type: "REST"
        base_url: "/api/v1"
        documentation: "OpenAPI/Swagger auto-generated"
  
  # Frontend technology details (future web interface)
  frontend:
    framework: "React"
    language: "TypeScript"
    build_tool: "Vite"
    package_manager: "npm"
    key_libraries:
      - name: "@supabase/supabase-js"
        version: "^2.0.0"
        purpose: "Database and auth client"
      - name: "react-query"
        version: "^4.0.0"
        purpose: "Data fetching and caching"
  
  # Deployment details
  deployment:
    strategy: "Containerized serverless functions"
    bundling: "Docker images for RunPod"
    cdn: "Supabase Storage for audio files"

# Global Specifications - Project-wide standards and configurations
global:
  # Design tokens for future UI components
  design_tokens:
    # Color palette - News/media theme
    colors:
      primary: "#1e40af"      # Professional news blue
      secondary: "#dc2626"    # Alert/breaking news red
      accent: "#059669"       # Success/published green
      text:
        primary: "#111827"    # Dark gray for readability
        secondary: "#6b7280"  # Medium gray for secondary text
      background:
        light: "#ffffff"      # Clean white background
        dark: "#1f2937"       # Dark mode background
      semantic:
        success: "#10b981"    # Success states
        warning: "#f59e0b"    # Warning states
        error: "#ef4444"      # Error states
        info: "#3b82f6"       # Information states
    
    # Typography system
    typography:
      font_family: "Inter, -apple-system, BlinkMacSystemFont, sans-serif"
      base_size: "16px"
      scale_ratio: 1.25
      weights:
        regular: 400
        medium: 500
        bold: 700
    
    # Spacing system
    spacing:
      base: "8px"
      scale:
        xs: "4px"    # 0.5x base
        sm: "8px"    # 1x base
        md: "16px"   # 2x base
        lg: "24px"   # 3x base
        xl: "32px"   # 4x base
    
    # Animation definitions
    animation:
      duration:
        fast: "150ms"
        normal: "300ms"
        slow: "500ms"
      easing:
        default: "cubic-bezier(0.4, 0, 0.2, 1)"
        in: "cubic-bezier(0.4, 0, 1, 1)"
        out: "cubic-bezier(0, 0, 0.2, 1)"
  
  # Accessibility standards
  accessibility:
    compliance: "WCAG 2.1 AA"
    color_contrast:
      minimum_ratio: "4.5:1"
    keyboard_navigation: true
    screen_reader_support: true
    focus_indicators:
      style: "outline"
      color: "#1e40af"
      width: "2px"
  
  # Responsive design configuration
  responsive:
    breakpoints:
      mobile: "max-width: 599px"
      tablet: "600px to 1023px"
      desktop: "min-width: 1024px"
    strategy: "mobile-first"
    container_widths:
      max_width: "1280px"
      padding: "16px"
  
  # Error handling patterns
  error_handling:
    strategies:
      client: "Toast notifications with retry options"
      server: "Structured error responses with logging"
    error_states:
      api:
        toast: true
        position: "top-right"
        timeout: 5000
      scraping:
        fallback: "Use summary from news feed"
        retry_attempts: 3
    fallbacks:
      images: "/assets/news-placeholder.png"
      data: "skeleton loading states"

  # Performance targets
  performance:
    metrics:
      api_response: "< 2s"    # API response time
      scraping_timeout: "30s" # Web scraping timeout
      concurrent_requests: "10" # Max concurrent scraping
    optimization:
      async_processing: true
      request_batching: true
      connection_pooling: true

  # Internationalization configuration
  i18n:
    default_language: "en"
    supported_languages: ["en", "fr"]  # English and French for Canada
    rtl_support: false
    date_format: "YYYY-MM-DD"
    number_format:
      decimal_separator: "."
      thousands_separator: ","

# Data Flow Architecture - How data flows through the application
data_flow:
  # Core data patterns
  patterns:
    core_strategy: "Event-driven async processing pipeline"
    data_fetching: "Multi-source aggregation with concurrent scraping"
    state_updates: "Database-first with real-time subscriptions"
  
  # Data sources
  sources:
    google_news:
      base_url: "https://news.google.com"
      rate_limits: "Respectful scraping with delays"
      filtering: "Canadian news sources only"
    web_scraping:
      timeout: "30 seconds per article"
      concurrent_limit: 10
      user_agent: "TKR-NewsBot/1.0"
    anthropic_api:
      base_url: "https://api.anthropic.com"
      authentication: "API key authentication"
      rate_limits: "Per API tier limits"
  
  # Caching strategy
  caching:
    strategy: "Database-backed with TTL"
    invalidation:
      events: ["new_session_created", "manual_refresh"]
    ttl:
      news_articles: "1 hour"
      processed_content: "24 hours"
  
  # Processing pipeline
  processing:
    stages:
      - "News collection from Google News"
      - "Article URL extraction and deduplication"
      - "Concurrent web scraping for full content"
      - "AI processing with host personalities"
      - "Database storage and audio file generation"

# Canadian Province Configuration
provinces:
  supported_provinces:
    - "Alberta"
    - "British Columbia" 
    - "Manitoba"
    - "New Brunswick"
    - "Newfoundland and Labrador"
    - "Northwest Territories"
    - "Nova Scotia"
    - "Nunavut"
    - "Ontario"
    - "Prince Edward Island"
    - "Quebec"
    - "Saskatchewan"
    - "Yukon"
  search_strategy: "Multiple search terms per province for diversity"
  content_filtering: "Canadian news sources prioritized"

# AI Host Personalities Configuration
ai_hosts:
  personalities:
    anchor:
      name: "Professional News Anchor"
      style: "Professional, authoritative, trustworthy"
      tone: "Clear, measured, objective"
      target_length: "30-60 seconds spoken"
    friend:
      name: "Friendly Neighbor"
      style: "Warm, conversational, relatable"
      tone: "Casual, friendly, engaging"
      target_length: "45-75 seconds spoken"
    newsreel:
      name: "1940s Newsreel Announcer"
      style: "Dramatic, theatrical, vintage"
      tone: "Bold, emphatic, larger-than-life"
      target_length: "30-45 seconds spoken"
  processing:
    model: "claude-3-haiku-20240307"
    temperature: 0.7
    max_tokens: 2000

# Deployment and DevOps Configuration
deployment:
  # Environment configurations
  environments:
    development:
      url: "http://localhost:8000"
      auto_deploy: false
      branch: "develop"
      database: "local_supabase"
    staging:
      url: "https://staging-api.tkr-news.com"
      auto_deploy: true
      branch: "staging"
      database: "staging_supabase"
    production:
      url: "https://api.tkr-news.com"
      auto_deploy: false
      branch: "main"
      database: "production_supabase"
  
  # Build process steps
  build_process:
    steps:
      - name: "Install dependencies"
        command: "pip install -r requirements.txt"
      - name: "Run tests"
        command: "pytest tests/"
      - name: "Build Docker image"
        command: "docker build -t tkr-news-gather ."
      - name: "Deploy to RunPod"
        command: "runpod deploy"
  
  # Monitoring configuration
  monitoring:
    services:
      - name: "RunPod Metrics"
        provider: "RunPod Dashboard"
      - name: "Supabase Analytics"
        provider: "Supabase Dashboard"
    alerts:
      - trigger: "API response time > 5s"
        notification: "Email to team"
      - trigger: "Error rate > 5%"
        notification: "Slack channel"

# Testing Strategy - Comprehensive testing approach
testing:
  # Unit testing configuration
  unit:
    framework: "pytest"
    coverage_targets:
      statements: 85
      branches: 80
      functions: 85
      lines: 85
  
  # Integration testing configuration
  integration:
    framework: "pytest-asyncio"
    key_flows:
      - "Complete news gathering pipeline"
      - "AI processing with different personalities"
      - "Database storage and retrieval"
  
  # End-to-end testing configuration
  e2e:
    framework: "pytest + httpx"
    critical_paths:
      - "Full API workflow from news fetch to processed output"
      - "Error handling and recovery scenarios"
  
  # Performance testing
  performance:
    tools:
      - "pytest-benchmark"
    budgets:
      - metric: "API response time"
        budget: "< 2 seconds"
      - metric: "Scraping success rate"
        budget: "> 90%"

# Security Considerations
security:
  # Authentication configuration
  authentication:
    method: "API key authentication"
    session_duration: "N/A - stateless API"
    refresh_mechanism: "API key rotation"
  
  # Data protection
  data_protection:
    encryption:
      in_transit: "TLS 1.3"
      at_rest: "Supabase encryption"
    pii_handling:
      fields:
        - name: "article_content"
          treatment: "Public news content - no PII expected"
        - name: "user_sessions"
          treatment: "Anonymized session tracking"
  
  # API Security
  api_security:
    rate_limiting: "100 requests per minute per API key"
    input_validation: "Strict parameter validation"
    output_sanitization: "Content sanitization for web display"
  
  # Compliance standards
  compliance:
    standards:
      - "Canadian privacy legislation awareness"
      - "Responsible web scraping practices"
    audit_logging:
      events:
        - "API requests and responses"
        - "Scraping activities and sources"
        - "AI processing requests"